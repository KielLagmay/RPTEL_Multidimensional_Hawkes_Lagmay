{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c1f2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "import threading\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from ast import literal_eval\n",
    "import datetime\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import pytz\n",
    "import json\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns\n",
    "from tick.plot import plot_hawkes_kernels, plot_point_process\n",
    "from tick.hawkes import HawkesExpKern, HawkesADM4, SimuHawkesExpKernels, SimuPoissonProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446c91ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(str(input()))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52d3904",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.drop(['D'], axis=1, inplace = True)\n",
    "#dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32852df",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestampColumns = ['A', 'C', 'L']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5503c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "startDate = datetime.strptime(str(input(\"Start Date (Format: YYYY-MM-DD): \")), \"%Y-%m-%d\").astimezone(pytz.utc)\n",
    "startDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eb73ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "endDate = datetime.strptime(str(input(\"End Date (Format: YYYY-MM-DD): \")), \"%Y-%m-%d\").astimezone(pytz.utc)\n",
    "endDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c62800",
   "metadata": {},
   "outputs": [],
   "source": [
    "dayAfterEndDate = float((time.mktime(endDate.timetuple()) / 3600) - (time.mktime(startDate.timetuple()) / 3600))\n",
    "dayAfterEndDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de60dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateActualIntensities(timestampList):\n",
    "    result = {}\n",
    "    for timePoint in timestampList:\n",
    "        if math.floor(timePoint) not in result.keys():\n",
    "            result[math.floor(timePoint)] = 0\n",
    "        result[math.floor(timePoint)] = result[math.floor(timePoint)] + 1\n",
    "    \n",
    "    return result\n",
    "\n",
    "for column in timestampColumns:\n",
    "    dataset[column] = dataset[column].apply(lambda x: literal_eval(x))\n",
    "    dataset[column] = dataset[column].apply(sorted)\n",
    "    dataset['actual_intensities_' + column] = dataset[column].apply(calculateActualIntensities)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdd53b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateAverageIntensityPerHour(intensityList):\n",
    "    result = 0\n",
    "    for h in intensityList.keys():\n",
    "        result = result + intensityList[h]\n",
    "    return result / (math.floor(dayAfterEndDate) + 1)\n",
    "\n",
    "for timestampColumn in timestampColumns:\n",
    "    dataset['average_intensity_' + timestampColumn] = dataset['actual_intensities_' + timestampColumn].apply(calculateAverageIntensityPerHour)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504ab70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculatePoissonIntensities(df):\n",
    "    learner = SimuPoissonProcess(intensities=np.array([df['average_intensity_' + timestampColumn] for timestampColumn in timestampColumns]), end_time=dayAfterEndDate)\n",
    "    learner.track_intensity(intensity_track_step = 1)\n",
    "    learner.simulate()\n",
    "    return learner.tracked_intensity\n",
    "\n",
    "dataset['intensities'] = dataset.apply(calculatePoissonIntensities, axis = 1)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2b580b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculatePoissonIntensityTimes(df):\n",
    "    learner = SimuPoissonProcess(intensities=np.array([df['average_intensity_' + timestampColumn] for timestampColumn in timestampColumns]), end_time=dayAfterEndDate)\n",
    "    learner.track_intensity(intensity_track_step = 1)\n",
    "    learner.simulate()\n",
    "    return learner.intensity_tracked_times\n",
    "\n",
    "dataset['intensity_times'] = dataset.apply(calculatePoissonIntensityTimes, axis = 1)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9851f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitResultsExpKern(overallResult, dimensions):\n",
    "    for i in range(0, len(dimensions)):\n",
    "        overallResult['intensities_' + dimensions[i]] = overallResult['intensities'].apply(lambda b: b[i].tolist())\n",
    "    \n",
    "    overallResult.drop(['intensities'], axis = 1, inplace = True)\n",
    "    overallResult['intensity_times'] = overallResult['intensity_times'].apply(lambda b: b.tolist())\n",
    "    \n",
    "    return overallResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d8ff63",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = splitResultsExpKern(dataset, timestampColumns)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ba4e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "for timestampColumn in timestampColumns:\n",
    "    dataset['intensities_' + timestampColumn] = dataset.apply(lambda df: dict(zip(df['intensity_times'], df['intensities_' + timestampColumn])), axis = 1)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89c2aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixTimestamps(df, column):\n",
    "    result = {}\n",
    "    for h in df[column].keys():\n",
    "        if math.floor(h) not in result.keys():\n",
    "            result[math.floor(h)] = 0\n",
    "        result[math.floor(h)] = result[math.floor(h)] + df[column][h]\n",
    "    return result\n",
    "\n",
    "for dim in timestampColumns:\n",
    "    dataset['intensities_' + dim] = dataset.apply(lambda df: fixTimestamps(df, 'intensities_' + dim), axis = 1)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b55259e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def completeTimestamps(df, colName):\n",
    "    result = {}\n",
    "    for t in range(0, math.floor(dayAfterEndDate) + 1):\n",
    "        if t not in df[colName].keys():\n",
    "            result[t] = 0\n",
    "        else:\n",
    "            result[t] = df[colName][t]\n",
    "    return result\n",
    "\n",
    "for colName in ['actual_intensities_', 'intensities_']:\n",
    "    for dim in timestampColumns:\n",
    "        dataset[colName + dim] = dataset.apply(lambda df: completeTimestamps(df, colName + dim), axis = 1)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926423bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "modalities = dataset['Modality'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fb8031",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineIntensityDictionaries(x, y):\n",
    "    combinedDictionary = {}\n",
    "    \n",
    "    for key in x.keys():\n",
    "        if key not in combinedDictionary.keys():\n",
    "            combinedDictionary[key] = 0\n",
    "        combinedDictionary[key] = combinedDictionary[key] + x[key]\n",
    "    for key in y.keys():\n",
    "        if key not in combinedDictionary.keys():\n",
    "            combinedDictionary[key] = 0\n",
    "        combinedDictionary[key] = combinedDictionary[key] + y[key]\n",
    "    \n",
    "    return combinedDictionary\n",
    "    \n",
    "\n",
    "def sumIntensities(series):\n",
    "    return reduce(combineIntensityDictionaries, series)\n",
    "\n",
    "intensityColumns = {}\n",
    "for dimension in timestampColumns:\n",
    "    intensityColumns['actual_intensities_' + dimension] = sumIntensities\n",
    "    intensityColumns['intensities_' + dimension] = sumIntensities\n",
    "\n",
    "intensityPlotDataset = dataset.groupby(['Modality']).agg(intensityColumns).reset_index()\n",
    "intensityPlotDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc38e38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "courseStudentCount = dataset.groupby(['Modality'])['course_code'].count().to_frame('total').reset_index()\n",
    "courseStudentCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c664773",
   "metadata": {},
   "outputs": [],
   "source": [
    "intensityPlotDataset = intensityPlotDataset.merge(courseStudentCount, on=['Modality'])\n",
    "intensityPlotDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43694e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAverageIntensities(df, column):\n",
    "    result = {}\n",
    "    for k in sorted([key for key in df[column].keys()]):\n",
    "        result[k] = df[column][k] / df['total']\n",
    "    return result\n",
    "\n",
    "for column in ['actual_intensities_' + dimension for dimension in timestampColumns] + ['intensities_' + dimension for dimension in timestampColumns]:\n",
    "    intensityPlotDataset[column] = intensityPlotDataset.apply(lambda df: getAverageIntensities(df, column), axis = 1)\n",
    "\n",
    "intensityPlotDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4437d00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for modality in modalities:\n",
    "    fig, axs = plt.subplots(len(timestampColumns), 1)\n",
    "    intensityPlotDatasetModality = intensityPlotDataset.loc[intensityPlotDataset['Modality'] == modality]\n",
    "    \n",
    "    for i in range(0, len(timestampColumns)):\n",
    "        axs[i].plot([t for t in intensityPlotDatasetModality.iloc[0]['actual_intensities_' + timestampColumns[i]].keys()], [v for v in intensityPlotDatasetModality.iloc[0]['actual_intensities_' + timestampColumns[i]].values()], color='tab:blue')\n",
    "        axs[i].plot([t for t in intensityPlotDatasetModality.iloc[0]['intensities_' + timestampColumns[i]].keys()], [v for v in intensityPlotDatasetModality.iloc[0]['intensities_' + timestampColumns[i]].values()], color='tab:orange')\n",
    "        axs[i].set_title(timestampColumns[i])\n",
    "    \n",
    "    for ax in axs.flat:\n",
    "        ax.set(xlabel='Time', ylabel='Intensity')\n",
    "    \n",
    "    fig.legend(handles=[Line2D([0], [0], color='tab:blue', label='Actual Intensities'), Line2D([0], [0], color='tab:orange', label='Est. Intensities')], loc='lower center')\n",
    "    fig.tight_layout(pad=1.0)\n",
    "    fig.set_figwidth(10)\n",
    "    fig.set_figheight(10)\n",
    "    fig.savefig(modality + '_Intensities_Poisson.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55adf89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dim in timestampColumns:\n",
    "    dataset['rmse_' + dim] = dataset.apply(lambda df: mean_squared_error([v for v in df['actual_intensities_' + dim].values()], [v for v in df['intensities_' + dim].values()], squared=False), axis = 1)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7662ff9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "averageAgg = {}\n",
    "for dim in timestampColumns:\n",
    "    averageAgg['rmse_' + dim] = np.mean\n",
    "\n",
    "rmseModalities = dataset.groupby(['Modality']).agg(averageAgg).reset_index()\n",
    "rmseModalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414ea131",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmseModalities.to_csv('RMSE_Poisson.csv', header = True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adfc4d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
