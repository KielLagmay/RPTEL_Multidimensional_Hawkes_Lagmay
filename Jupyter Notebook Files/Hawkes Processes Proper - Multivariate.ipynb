{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c1f2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABCMeta\n",
    "from functools import reduce\n",
    "import threading\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy import stats\n",
    "from ast import literal_eval\n",
    "import datetime\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import pytz\n",
    "import json\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns\n",
    "from tick.plot import plot_hawkes_kernels, plot_point_process\n",
    "from tick.hawkes import HawkesExpKern, HawkesADM4, SimuHawkesExpKernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446c91ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(str(input()))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52d3904",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.drop(['D'], axis=1, inplace = True)\n",
    "#dataset\n",
    "len(dataset['course_code'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a8e700",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset['metadata_context_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d420c818",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset['metadata_user_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32852df",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestampColumns = ['A', 'C', 'L']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5503c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "startDate = datetime.strptime(str(input(\"Start Date (Format: YYYY-MM-DD): \")), \"%Y-%m-%d\").astimezone(pytz.utc)\n",
    "startDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eb73ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "endDate = datetime.strptime(str(input(\"End Date (Format: YYYY-MM-DD): \")), \"%Y-%m-%d\").astimezone(pytz.utc)\n",
    "endDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c62800",
   "metadata": {},
   "outputs": [],
   "source": [
    "dayAfterEndDate = float((time.mktime(endDate.timetuple()) / 3600) - (time.mktime(startDate.timetuple()) / 3600))\n",
    "dayAfterEndDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de60dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateActualIntensities(timestampList):\n",
    "    result = {}\n",
    "    for timePoint in timestampList:\n",
    "        if math.floor(timePoint) not in result.keys():\n",
    "            result[math.floor(timePoint)] = 0\n",
    "        result[math.floor(timePoint)] = result[math.floor(timePoint)] + 1\n",
    "    \n",
    "    return result\n",
    "\n",
    "for column in timestampColumns:\n",
    "    dataset[column] = dataset[column].apply(lambda x: literal_eval(x))\n",
    "    dataset[column] = dataset[column].apply(sorted)\n",
    "    dataset['actual_intensities_' + column] = dataset[column].apply(calculateActualIntensities)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760fd6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineColumns(df, columns):\n",
    "    return [np.array(df[column], dtype=np.double) for column in columns]\n",
    "\n",
    "dataset['timestamps'] = dataset.apply(lambda df: combineColumns(df, timestampColumns), axis = 1)\n",
    "dataset['timestamps_train'] = dataset['timestamps']\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b9ebc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimateBestDecay(timestamps):\n",
    "    highestScore = None\n",
    "    bestDecay = None\n",
    "    for d in range(1, 11):\n",
    "        learner = HawkesExpKern(decays=d, penalty='elasticnet', elastic_net_ratio=0.5)\n",
    "        learner.fit(timestamps)\n",
    "        score = learner.score(timestamps, end_times=dayAfterEndDate)\n",
    "        if((highestScore == None) or (score >= highestScore)):\n",
    "            highestScore = score\n",
    "            bestDecay = d\n",
    "    \n",
    "    return bestDecay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9adb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    decays = pd.read_csv(str(input()))\n",
    "    dataset = dataset.merge(decays, on=['metadata_context_id', 'metadata_user_id'])\n",
    "except:\n",
    "    dataset['decay'] = dataset['timestamps_train'].apply(estimateBestDecay)\n",
    "    dataset[['metadata_context_id', 'metadata_user_id', 'decay']].to_csv('MultivariateHawkesDecays_Intercession_2022.csv', header = True, index = False)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf04d44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHawkesProcessExpKernAdjacency(df):\n",
    "    learner = HawkesExpKern(decays=df['decay'], penalty='elasticnet', elastic_net_ratio=0.5)\n",
    "    learner.fit(df['timestamps_train'])\n",
    "    return learner.adjacency\n",
    "\n",
    "dataset['adjacency'] = dataset.apply(getHawkesProcessExpKernAdjacency, axis = 1)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c62bc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHawkesProcessExpKernBaseline(df):\n",
    "    learner = HawkesExpKern(decays=df['decay'], penalty='elasticnet', elastic_net_ratio=0.5)\n",
    "    learner.fit(df['timestamps_train'])\n",
    "    return learner.baseline\n",
    "\n",
    "dataset['baseline'] = dataset.apply(getHawkesProcessExpKernBaseline, axis = 1)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c7dde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHawkesProcessExpKernIntensities(df):\n",
    "    learner = HawkesExpKern(decays=df['decay'], penalty='elasticnet', elastic_net_ratio=0.5)\n",
    "    learner.fit(df['timestamps_train'])\n",
    "    intensities, intensity_times = learner.estimated_intensity(df['timestamps'], intensity_track_step=1, end_time=dayAfterEndDate)\n",
    "    return intensities\n",
    "\n",
    "dataset['intensities'] = dataset.apply(getHawkesProcessExpKernIntensities, axis = 1)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685177bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHawkesProcessExpKernIntensityTimes(df):\n",
    "    learner = HawkesExpKern(decays=df['decay'], penalty='elasticnet', elastic_net_ratio=0.5)\n",
    "    learner.fit(df['timestamps_train'])\n",
    "    intensities, intensity_times = learner.estimated_intensity(df['timestamps'], intensity_track_step=1, end_time=dayAfterEndDate)\n",
    "    return intensity_times\n",
    "\n",
    "dataset['intensity_times'] = dataset.apply(getHawkesProcessExpKernIntensityTimes, axis = 1)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0ce54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitResultsExpKern(overallResult, dimensions):\n",
    "    for i in range(0, len(dimensions)):\n",
    "        overallResult['baseline_' + dimensions[i]] = overallResult['baseline'].apply(lambda b: b.tolist()[i])\n",
    "        overallResult['intensities_' + dimensions[i]] = overallResult['intensities'].apply(lambda b: b[i].tolist())\n",
    "        \n",
    "        for j in range(0, len(dimensions)):\n",
    "            overallResult['influence_' + dimensions[i] + dimensions[j]] = overallResult['adjacency'].apply(lambda a: a.tolist()[i][j])\n",
    "    \n",
    "    overallResult.drop(['baseline', 'adjacency', 'intensities'], axis = 1, inplace = True)\n",
    "    overallResult['intensity_times'] = overallResult['intensity_times'].apply(lambda b: b.tolist())\n",
    "    \n",
    "    return overallResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca06d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = splitResultsExpKern(dataset, timestampColumns)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bd69a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alignIntensityToTimestamps(df, dim):\n",
    "    return dict(zip(df['intensity_times'], df['intensities_' + dim]))\n",
    "\n",
    "for dim in timestampColumns:\n",
    "    dataset['intensities_' + dim] = dataset.apply(lambda df: alignIntensityToTimestamps(df, dim), axis = 1)\n",
    "    \n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff5f812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixTimestamps(df, column):\n",
    "    result = {}\n",
    "    for h in df[column].keys():\n",
    "        if math.floor(h) not in result.keys():\n",
    "            result[math.floor(h)] = 0\n",
    "        result[math.floor(h)] = result[math.floor(h)] + df[column][h]\n",
    "    return result\n",
    "\n",
    "for dim in timestampColumns:\n",
    "    dataset['intensities_' + dim] = dataset.apply(lambda df: fixTimestamps(df, 'intensities_' + dim), axis = 1)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47152615",
   "metadata": {},
   "outputs": [],
   "source": [
    "def completeTimestamps(df, colName):\n",
    "    result = {}\n",
    "    for t in range(0, math.floor(dayAfterEndDate) + 1):\n",
    "        if t not in df[colName].keys():\n",
    "            result[t] = 0\n",
    "        else:\n",
    "            result[t] = df[colName][t]\n",
    "    return result\n",
    "\n",
    "for colName in ['actual_intensities_', 'intensities_']:\n",
    "    for dim in timestampColumns:\n",
    "        dataset[colName + dim] = dataset.apply(lambda df: completeTimestamps(df, colName + dim), axis = 1)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352ff58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "modalities = dataset['Modality'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae490bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineIntensityDictionaries(x, y):\n",
    "    combinedDictionary = {}\n",
    "    \n",
    "    for key in x.keys():\n",
    "        if key not in combinedDictionary.keys():\n",
    "            combinedDictionary[key] = 0\n",
    "        combinedDictionary[key] = combinedDictionary[key] + x[key]\n",
    "    for key in y.keys():\n",
    "        if key not in combinedDictionary.keys():\n",
    "            combinedDictionary[key] = 0\n",
    "        combinedDictionary[key] = combinedDictionary[key] + y[key]\n",
    "    \n",
    "    return combinedDictionary\n",
    "    \n",
    "\n",
    "def sumIntensities(series):\n",
    "    return reduce(combineIntensityDictionaries, series)\n",
    "\n",
    "intensityColumns = {}\n",
    "for dimension in timestampColumns:\n",
    "    intensityColumns['actual_intensities_' + dimension] = sumIntensities\n",
    "    intensityColumns['intensities_' + dimension] = sumIntensities\n",
    "\n",
    "intensityPlotDataset = dataset.groupby(['Modality']).agg(intensityColumns).reset_index()\n",
    "intensityPlotDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfea0101",
   "metadata": {},
   "outputs": [],
   "source": [
    "courseStudentCount = dataset.groupby(['Modality'])['course_code'].count().to_frame('total').reset_index()\n",
    "courseStudentCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f991131b",
   "metadata": {},
   "outputs": [],
   "source": [
    "intensityPlotDataset = intensityPlotDataset.merge(courseStudentCount, on=['Modality'])\n",
    "intensityPlotDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e872b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAverageIntensities(df, column):\n",
    "    result = {}\n",
    "    for k in sorted([key for key in df[column].keys()]):\n",
    "        result[k] = df[column][k] / df['total']\n",
    "    return result\n",
    "\n",
    "for column in ['actual_intensities_' + dimension for dimension in timestampColumns] + ['intensities_' + dimension for dimension in timestampColumns]:\n",
    "    intensityPlotDataset[column] = intensityPlotDataset.apply(lambda df: getAverageIntensities(df, column), axis = 1)\n",
    "\n",
    "intensityPlotDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57eee634",
   "metadata": {},
   "outputs": [],
   "source": [
    "for modality in modalities:\n",
    "    fig, axs = plt.subplots(len(timestampColumns), 1)\n",
    "    intensityPlotDatasetModality = intensityPlotDataset.loc[intensityPlotDataset['Modality'] == modality]\n",
    "    \n",
    "    for i in range(0, len(timestampColumns)):\n",
    "        axs[i].plot([t for t in intensityPlotDatasetModality.iloc[0]['actual_intensities_' + timestampColumns[i]].keys()], [v for v in intensityPlotDatasetModality.iloc[0]['actual_intensities_' + timestampColumns[i]].values()], color='tab:blue')\n",
    "        axs[i].plot([t for t in intensityPlotDatasetModality.iloc[0]['intensities_' + timestampColumns[i]].keys()], [v for v in intensityPlotDatasetModality.iloc[0]['intensities_' + timestampColumns[i]].values()], color='tab:orange')\n",
    "        axs[i].set_title(timestampColumns[i])\n",
    "    \n",
    "    for ax in axs.flat:\n",
    "        ax.set(xlabel='Time', ylabel='Intensity')\n",
    "    \n",
    "    fig.legend(handles=[Line2D([0], [0], color='tab:blue', label='Actual Intensities'), Line2D([0], [0], color='tab:orange', label='Est. Intensities')], loc='lower center')\n",
    "    fig.tight_layout(pad=1.0)\n",
    "    fig.set_figwidth(10)\n",
    "    fig.set_figheight(10)\n",
    "    fig.savefig(modality + '_Intensities_Multivariate.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b55259e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dim in timestampColumns:\n",
    "    dataset['rmse_' + dim] = dataset.apply(lambda df: mean_squared_error([v for v in df['actual_intensities_' + dim].values()], [v for v in df['intensities_' + dim].values()], squared=False), axis = 1)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e22586",
   "metadata": {},
   "outputs": [],
   "source": [
    "averageAgg = {}\n",
    "for dim in timestampColumns:\n",
    "    averageAgg['rmse_' + dim] = np.mean\n",
    "\n",
    "rmseModalities = dataset.groupby(['Modality']).agg(averageAgg).reset_index()\n",
    "rmseModalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54438eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for modality in modalities:\n",
    "    fig, axs = plt.subplots(len(timestampColumns), 1)\n",
    "        \n",
    "    hawkesProcessResult_B_subset = dataset.loc[(dataset['Modality'] == modality)]\n",
    "    for i in range(0, len(timestampColumns)):\n",
    "        axs[i].scatter(hawkesProcessResult_B_subset['est_course_grade'], hawkesProcessResult_B_subset['baseline_' + timestampColumns[i]], s = 3)\n",
    "        axs[i].set_title(timestampColumns[i])\n",
    "    \n",
    "    for ax in axs.flat:\n",
    "        ax.set(xlabel='Est. Course Grade', ylabel='Base Intensity')\n",
    "\n",
    "    fig.tight_layout(pad=1.0)\n",
    "    fig.set_figwidth(10)\n",
    "    fig.set_figheight(10)\n",
    "    fig.savefig(modality + '_B.png')\n",
    "    plt.close()\n",
    "'''\n",
    "rmseModalities['model'] = 'Multivariate Hawkes'\n",
    "rmseModalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1756cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "low_q = dataset.groupby(['Modality']).agg({'est_course_grade': lambda series: np.quantile(series, 0.25)}).reset_index()\n",
    "low_q = low_q.rename(columns = {'est_course_grade': 'low_q'})\n",
    "low_q\n",
    "'''\n",
    "rmseModalitiesUnivariate = pd.read_csv(str(input()))\n",
    "rmseModalitiesUnivariate['model'] = 'Univariate Hawkes'\n",
    "rmseModalities = pd.concat([rmseModalities, rmseModalitiesUnivariate])\n",
    "rmseModalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166f1706",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "high_q = dataset.groupby(['Modality']).agg({'est_course_grade': lambda series: np.quantile(series, 0.75)}).reset_index()\n",
    "high_q = high_q.rename(columns = {'est_course_grade': 'high_q'})\n",
    "high_q\n",
    "'''\n",
    "rmseModalitiesPoisson = pd.read_csv(str(input()))\n",
    "rmseModalitiesPoisson['model'] = 'Poisson'\n",
    "rmseModalities = pd.concat([rmseModalities, rmseModalitiesPoisson])\n",
    "rmseModalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1641bd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "dataset = dataset.merge(low_q, on=['Modality'])\n",
    "dataset = dataset.merge(high_q, on=['Modality'])\n",
    "dataset['is_low_q'] = dataset.apply(lambda df: df['est_course_grade'] < df['low_q'], axis = 1)\n",
    "dataset['is_high_q'] = dataset.apply(lambda df: df['est_course_grade'] >= df['high_q'], axis = 1)\n",
    "dataset\n",
    "'''\n",
    "for modality in modalities:\n",
    "    rmseModalitiesSubset = rmseModalities.loc[rmseModalities['Modality'] == modality]\n",
    "    rmseModalitiesSubset.drop(['Modality'], axis = 1, inplace = True)\n",
    "    rmseModalitiesSubset = rmseModalitiesSubset.melt(id_vars = ['model'], var_name = 'dimension', value_name = 'rmse')\n",
    "    rmseModalitiesSubset['dimension'] = rmseModalitiesSubset['dimension'].apply(lambda x: x.split(\"_\")[-1])\n",
    "    \n",
    "    dimensions = sorted(timestampColumns)\n",
    "    x = np.arange(len(dimensions))\n",
    "    width = 0.25\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    models = rmseModalitiesSubset['model'].unique()\n",
    "    for i in range(0, len(models)):\n",
    "        offset = width * i\n",
    "        rmseModalitiesSubsetModel = rmseModalitiesSubset.loc[rmseModalitiesSubset['model'] == models[i]].sort_values(by='dimension')\n",
    "        rects = ax.bar(x + offset, rmseModalitiesSubsetModel['rmse'], width, label=models[i])\n",
    "    \n",
    "    ax.set_ylabel('Root Mean Squared Error')\n",
    "    ax.set_xlabel('Multidimensional Hawkes Dimensions')\n",
    "    ax.set_xticks(x + width, dimensions)\n",
    "    fig.legend(loc='lower center', ncols=3)\n",
    "    plt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9, wspace=0.4, hspace=0.4)\n",
    "    fig.set_figwidth(10)\n",
    "    fig.set_figheight(10)\n",
    "    fig.savefig('GoodnessOfFit_' + modality + '.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b04b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for modality in modalities:\n",
    "    fig, axs = plt.subplots(len(timestampColumns), 1)\n",
    "    \n",
    "    hawkesProcessResult_B_subset = dataset.loc[dataset['Modality'] == modality]\n",
    "    for i in range(0, len(timestampColumns)):\n",
    "        sns.histplot(ax=axs[i], data=hawkesProcessResult_B_subset.loc[hawkesProcessResult_B_subset['is_high_q'] == True]['baseline_' + timestampColumns[i]], label='high', kde=True)\n",
    "        sns.histplot(ax=axs[i], data=hawkesProcessResult_B_subset.loc[hawkesProcessResult_B_subset['is_low_q'] == True]['baseline_' + timestampColumns[i]], label='low', kde=True)\n",
    "        axs[i].set_title(timestampColumns[i])\n",
    "            \n",
    "    for ax in axs.flat:\n",
    "        ax.set(xlabel='Base Intensity')\n",
    "\n",
    "    handles, labels = axs.flat[-1].get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, loc='lower center')\n",
    "    fig.tight_layout(pad=1.0)\n",
    "    fig.set_figwidth(10)\n",
    "    fig.set_figheight(10)\n",
    "    fig.savefig(modality + '_B_histplot.png')\n",
    "    plt.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d20de04",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for modality in modalities:\n",
    "    fig, axs = plt.subplots(len(timestampColumns), len(timestampColumns))\n",
    "    \n",
    "    hawkesProcessResult_A_subset = dataset.loc[dataset['Modality'] == modality]\n",
    "        \n",
    "    for i in range(0, len(timestampColumns)):\n",
    "        for j in range(0, len(timestampColumns)):\n",
    "            axs[i, j].scatter(hawkesProcessResult_A_subset['est_course_grade'], hawkesProcessResult_A_subset['adjacency_' + timestampColumns[i] + \"_\" + timestampColumns[j]])\n",
    "            axs[i, j].set_ylabel(timestampColumns[i] + \"-\" + timestampColumns[j])\n",
    "    \n",
    "    for ax in axs.flat:\n",
    "        ax.set(xlabel='Est. Course Grade')\n",
    "\n",
    "    plt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9, wspace=0.4, hspace=0.4)\n",
    "    fig.set_figwidth(30)\n",
    "    fig.set_figheight(30)\n",
    "    fig.savefig(modality + '_A.png')\n",
    "    plt.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24948ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for modality in modalities:\n",
    "    fig, axs = plt.subplots(len(timestampColumns), len(timestampColumns))\n",
    "    \n",
    "    hawkesProcessResult_A_subset = dataset.loc[dataset['Modality'] == modality]\n",
    "        \n",
    "    for i in range(0, len(timestampColumns)):\n",
    "        for j in range(0, len(timestampColumns)):\n",
    "            sns.kdeplot(ax=axs[i, j], data=hawkesProcessResult_A_subset.loc[hawkesProcessResult_A_subset['is_high_q'] == True]['adjacency_' + timestampColumns[i] + \"_\" + timestampColumns[j]], label='high')\n",
    "            sns.rugplot(ax=axs[i, j], data=hawkesProcessResult_A_subset.loc[hawkesProcessResult_A_subset['is_high_q'] == True]['adjacency_' + timestampColumns[i] + \"_\" + timestampColumns[j]], label='high')\n",
    "                \n",
    "            sns.kdeplot(ax=axs[i, j], data=hawkesProcessResult_A_subset.loc[hawkesProcessResult_A_subset['is_low_q'] == True]['adjacency_' + timestampColumns[i] + \"_\" + timestampColumns[j]], label='low')\n",
    "            sns.rugplot(ax=axs[i, j], data=hawkesProcessResult_A_subset.loc[hawkesProcessResult_A_subset['is_low_q'] == True]['adjacency_' + timestampColumns[i] + \"_\" + timestampColumns[j]], label='low')\n",
    "            axs[i, j].set_xlabel(timestampColumns[i] + \"-\" + timestampColumns[j])\n",
    "            \n",
    "    handles, labels = axs.flat[-1].get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, loc='lower center')\n",
    "    plt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9, wspace=0.4, hspace=0.4)\n",
    "    fig.set_figwidth(30)\n",
    "    fig.set_figheight(30)\n",
    "    fig.savefig(modality + '_A_histplot.png')\n",
    "    plt.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa54012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjacencyColumns():\n",
    "    result = []\n",
    "    for i in timestampColumns:\n",
    "        for j in timestampColumns:\n",
    "            result.append('influence_' + i + j)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7bca0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "hawkesProcessResultRank = pd.DataFrame()\n",
    "for modality in modalities:\n",
    "    hawkesProcessResultSubset = dataset.loc[dataset['Modality'] == modality]\n",
    "    for column in ['baseline_' + dim for dim in timestampColumns] + adjacencyColumns() + ['decay']:\n",
    "        hawkesProcessResultSubset[column + \"_rank\"] = hawkesProcessResultSubset[column].rank(ascending=False)\n",
    "    hawkesProcessResultRank = hawkesProcessResultRank.append(hawkesProcessResultSubset)\n",
    "\n",
    "hawkesProcessResultRank\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4470fc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "hawkesProcessSpearmanCorrelation = pd.DataFrame()\n",
    "\n",
    "for modality in modalities:\n",
    "    hawkesProcessResultSubset = dataset.loc[dataset['Modality'] == modality]\n",
    "    for columnY in ['baseline_' + dim for dim in timestampColumns] + adjacencyColumns() + ['decay']:\n",
    "        for columnX in ['baseline_' + dim for dim in timestampColumns] + adjacencyColumns() + ['decay']:\n",
    "            spearmanCorrelationResult = stats.spearmanr(hawkesProcessResultSubset[columnX], hawkesProcessResultSubset[columnY])\n",
    "            hawkesProcessSpearmanCorrelation = hawkesProcessSpearmanCorrelation.append(pd.DataFrame.from_dict([{'Modality': modality, 'X': columnX, 'Y': columnY, 'coefficient': spearmanCorrelationResult.correlation, 'p': spearmanCorrelationResult.pvalue}]), ignore_index = True)\n",
    "\n",
    "hawkesProcessSpearmanCorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f7b0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for modality in modalities:\n",
    "    fig, axs = plt.subplots(2, 1)\n",
    "        \n",
    "    hawkesProcessResultSubset = hawkesProcessSpearmanCorrelation.loc[hawkesProcessSpearmanCorrelation['Modality'] == modality]\n",
    "    hawkesProcessResultSubset.drop(['Modality'], axis = 1, inplace = True)\n",
    "            \n",
    "    hawkesProcessResultSubsetCoeff = hawkesProcessResultSubset[['X', 'Y', 'coefficient']]\n",
    "    maxCoefficient = max(abs(min(hawkesProcessResultSubsetCoeff['coefficient'])), abs(max(hawkesProcessResultSubsetCoeff['coefficient'])))\n",
    "    hawkesProcessResultSubsetCoeff = hawkesProcessResultSubsetCoeff.pivot(index='Y', columns='X', values='coefficient')\n",
    "    sns.heatmap(hawkesProcessResultSubsetCoeff, ax=axs[0], annot=True, fmt=\".2f\", xticklabels=True, yticklabels=True, cmap=sns.color_palette(\"coolwarm\", as_cmap=True), vmin=-maxCoefficient, vmax=maxCoefficient, square=True, linewidths=2, linecolor='w')\n",
    "    axs[0].set_title(\"Coefficient\")\n",
    "    axs[0].set_xlabel(\"\")\n",
    "    axs[0].set_ylabel(\"\")\n",
    "            \n",
    "    hawkesProcessResultSubsetP = hawkesProcessResultSubset[['X', 'Y', 'p']]\n",
    "    hawkesProcessResultSubsetP = hawkesProcessResultSubsetP.pivot(index='Y', columns='X', values='p')\n",
    "    sns.heatmap(hawkesProcessResultSubsetP, ax=axs[1], annot=True, fmt=\".2f\", xticklabels=True, yticklabels=True, cmap=sns.light_palette(\"seagreen\", reverse=True, as_cmap=True), square=True, linewidths=2, linecolor='w')\n",
    "    axs[1].set_title(\"P-Value\")\n",
    "    axs[1].set_xlabel(\"\")\n",
    "    axs[1].set_ylabel(\"\")\n",
    "        \n",
    "    plt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9, wspace=0.4, hspace=0.4)\n",
    "    fig.set_figwidth(30)\n",
    "    fig.set_figheight(30)\n",
    "    fig.savefig(modality + '_spearmans_corr.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9eb3707",
   "metadata": {},
   "outputs": [],
   "source": [
    "hawkesProcessSpearmanCorrelation['XY'] = hawkesProcessSpearmanCorrelation.apply(lambda df: df['X'] + '-' + df['Y'] if df['X'] < df['Y'] else df['Y'] + '-' + df['X'], axis = 1)\n",
    "hawkesProcessSpearmanCorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0958c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "hawkesProcessSpearmanCorrelationTopCorrs = hawkesProcessSpearmanCorrelation.drop_duplicates(subset=['Modality', 'XY'])\n",
    "hawkesProcessSpearmanCorrelationTopCorrs = hawkesProcessSpearmanCorrelationTopCorrs.loc[(hawkesProcessSpearmanCorrelation['p'] <= 0.05) & (hawkesProcessSpearmanCorrelation['X'].isin(adjacencyColumns())) & (hawkesProcessSpearmanCorrelation['Y'].isin(adjacencyColumns()))]\n",
    "hawkesProcessSpearmanCorrelationTopCorrs['is_self'] = hawkesProcessSpearmanCorrelationTopCorrs.apply(lambda df: df['X'] == df['Y'], axis = 1)\n",
    "hawkesProcessSpearmanCorrelationTopCorrs = hawkesProcessSpearmanCorrelationTopCorrs.loc[hawkesProcessSpearmanCorrelationTopCorrs['is_self'] == False]\n",
    "hawkesProcessSpearmanCorrelationTopCorrs.drop(['is_self', 'X', 'Y'], axis = 1, inplace = True)\n",
    "\n",
    "for column in ['coefficient', 'p']:\n",
    "    hawkesProcessSpearmanCorrelationTopCorrs[column] = hawkesProcessSpearmanCorrelationTopCorrs[column].apply(lambda x: round(x, 2))\n",
    "\n",
    "hawkesProcessSpearmanCorrelationTopCorrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5080d279",
   "metadata": {},
   "outputs": [],
   "source": [
    "hawkesProcessSpearmanCorrelationTopCorrs.loc[hawkesProcessSpearmanCorrelationTopCorrs['Modality'] == '(FULLY ONLINE)'].sort_values('coefficient', ascending=False).head(3).to_csv(\"MultidimensionalHawkesParameterCorr_FullyOnline_Top3_Positive.csv\", header = True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7df247",
   "metadata": {},
   "outputs": [],
   "source": [
    "hawkesProcessSpearmanCorrelationTopCorrs.loc[hawkesProcessSpearmanCorrelationTopCorrs['Modality'] == '(FULLY ONLINE)'].sort_values('coefficient', ascending=True).head(3).to_csv(\"MultidimensionalHawkesParameterCorr_FullyOnline_Top3_Negative.csv\", header = True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5425fabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "hawkesProcessSpearmanCorrelationTopCorrs.loc[hawkesProcessSpearmanCorrelationTopCorrs['Modality'] == '(HYBRID)'].sort_values('coefficient', ascending=False).head(3).to_csv(\"MultidimensionalHawkesParameterCorr_Hybrid_Top3_Positive.csv\", header = True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dded64",
   "metadata": {},
   "outputs": [],
   "source": [
    "hawkesProcessSpearmanCorrelationTopCorrs.loc[hawkesProcessSpearmanCorrelationTopCorrs['Modality'] == '(HYBRID)'].sort_values('coefficient', ascending=True).head(3).to_csv(\"MultidimensionalHawkesParameterCorr_Hybrid_Top3_Negative.csv\", header = True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0aebb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "for modality in modalities:\n",
    "    fig, axs = plt.subplots(len(timestampColumns), 1)\n",
    "    \n",
    "    hawkesProcessResult_A_subset = dataset.loc[dataset['Modality'] == modality]\n",
    "        \n",
    "    for i in range(0, len(timestampColumns)):\n",
    "        sns.kdeplot(ax=axs[i], data=hawkesProcessResult_A_subset['influence_' + timestampColumns[i] + timestampColumns[i]])\n",
    "        axs[i].set_xlabel('influence_' + timestampColumns[i])\n",
    "            \n",
    "    handles, labels = axs.flat[-1].get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, loc='lower center')\n",
    "    plt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9, wspace=0.4, hspace=0.4)\n",
    "    fig.set_figwidth(30)\n",
    "    fig.set_figheight(30)\n",
    "    fig.savefig(modality + '_influence_density.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a96c6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterCourseStudents = dataset[['metadata_context_id', 'metadata_user_id', 'Modality', 'course_code'] + ['influence_' + dim + dim for dim in timestampColumns]]\n",
    "clusterCourseStudents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba84121",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterCourseStudentsResults = pd.DataFrame()\n",
    "\n",
    "for modality in modalities:\n",
    "    clusterCourseStudentsModality = clusterCourseStudents.loc[clusterCourseStudents['Modality'] == modality]\n",
    "    clusterBy = np.array(list(zip(clusterCourseStudentsModality['influence_AA'], clusterCourseStudentsModality['influence_CC'], clusterCourseStudentsModality['influence_LL'])))\n",
    "    \n",
    "    learner = KMeans(n_clusters = 2, max_iter = 1000).fit(clusterBy)\n",
    "    clusterCourseStudentsModality['cluster'] = learner.labels_.tolist()\n",
    "    clusterCourseStudentsResults = clusterCourseStudentsResults.append(clusterCourseStudentsModality, ignore_index = True)\n",
    "\n",
    "clusterCourseStudentsResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a417989",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.merge(clusterCourseStudentsResults[['metadata_context_id', 'metadata_user_id', 'Modality', 'course_code', 'cluster']], on=['metadata_context_id', 'metadata_user_id', 'Modality', 'course_code'])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbce382",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAggregatedInfluence(df, iDim):\n",
    "    aggInfluence = 0\n",
    "    for jDim in timestampColumns:\n",
    "        aggInfluence = aggInfluence + df['influence_' + iDim + jDim]\n",
    "    return aggInfluence / len(timestampColumns)\n",
    "\n",
    "for iDim in timestampColumns:\n",
    "    dataset['agg_influence_' + iDim] = dataset.apply(lambda df: getAggregatedInfluence(df, iDim), axis = 1)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb16324",
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsForConversionToList = {}\n",
    "for iDim in timestampColumns:\n",
    "    columnsForConversionToList['baseline_' + iDim] = list\n",
    "    columnsForConversionToList['agg_influence_' + iDim] = list\n",
    "    for jDim in timestampColumns:\n",
    "        columnsForConversionToList['influence_' + iDim + jDim] = list\n",
    "columnsForConversionToList['decay'] = list\n",
    "\n",
    "clusterHawkesParameterDiff = dataset.groupby(['Modality', 'cluster']).agg(columnsForConversionToList).reset_index()\n",
    "clusterHawkesParameterDiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dca5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterHawkesParameterDiffResults = pd.DataFrame()\n",
    "\n",
    "for modality in modalities:\n",
    "    clusterHawkesParameterDiffModality = clusterHawkesParameterDiff.loc[clusterHawkesParameterDiff['Modality'] == modality]\n",
    "    clusterHawkesParameterDiffModality.drop(['Modality'], axis = 1, inplace = True)\n",
    "    \n",
    "    clusterHawkesParameterDiffModality = clusterHawkesParameterDiffModality.set_index('cluster').transpose().reset_index()\n",
    "    clusterHawkesParameterDiffModality['kruskal_stats'] = clusterHawkesParameterDiffModality.apply(lambda df: stats.kruskal(df[0], df[1]).statistic, axis = 1)\n",
    "    clusterHawkesParameterDiffModality['kruskal_pval'] = clusterHawkesParameterDiffModality.apply(lambda df: stats.kruskal(df[0], df[1]).pvalue, axis = 1)\n",
    "    clusterHawkesParameterDiffModality['Modality'] = modality\n",
    "    clusterHawkesParameterDiffResults = clusterHawkesParameterDiffResults.append(clusterHawkesParameterDiffModality, ignore_index = True)\n",
    "    \n",
    "clusterHawkesParameterDiffResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c9f629",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterHawkesParameterDiffResults.drop([0, 1], axis = 1, inplace = True)\n",
    "clusterHawkesParameterDiffResults['is_significant'] = clusterHawkesParameterDiffResults['kruskal_pval'].apply(lambda x: x <= 0.001)\n",
    "clusterHawkesParameterDiffResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499c8e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterHawkesParameterDiffResults['color'] = clusterHawkesParameterDiffResults['is_significant'].apply(lambda x: 'tab:blue' if x else 'tab:gray')\n",
    "clusterHawkesParameterDiffResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69689e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "for modality in modalities:\n",
    "    clusterHawkesParameterDiffResultsModality = clusterHawkesParameterDiffResults.loc[(clusterHawkesParameterDiffResults['Modality'] == modality) & (~(clusterHawkesParameterDiffResults['index'] == 'decay'))].sort_values(by=['kruskal_stats'])\n",
    "    clusterHawkesParameterDiffResultsModality.drop(['Modality'], axis = 1, inplace = True)\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.barh(clusterHawkesParameterDiffResultsModality['index'], clusterHawkesParameterDiffResultsModality['kruskal_stats'], color=clusterHawkesParameterDiffResultsModality['color'])\n",
    "    ax.set_xlabel('Kruskal-Wallis Coefficient')\n",
    "    ax.set_ylabel('Multidimensional Hawkes Parameters')\n",
    "    fig.legend(handles=[Line2D([0], [0], color='tab:blue', label='P-Value <= 0.001'), Line2D([0], [0], color='tab:gray', label='P-Value > 0.001')], loc='lower center')\n",
    "    plt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9, wspace=0.4, hspace=0.4)\n",
    "    fig.set_figwidth(50)\n",
    "    fig.set_figheight(10)\n",
    "    fig.savefig('ClusterHawkesParameterDiffResults_' + modality + '.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823ddb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clusterHawkesParameterDiffResults.drop(['kruskal_pval'], axis = 1).pivot(index = 'Modality', columns = 'index', values = 'kruskal_stats').reset_index().to_csv(\"MultivariateHawkes_Kruskal_Results_Stats.csv\", header = True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fd2e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clusterHawkesParameterDiffResults.drop(['kruskal_stats'], axis = 1).pivot(index = 'Modality', columns = 'index', values = 'kruskal_pval').reset_index().to_csv(\"MultivariateHawkes_Kruskal_Results_PValue.csv\", header = True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7958f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsForAveragingList = {}\n",
    "for iDim in timestampColumns:\n",
    "    columnsForAveragingList['baseline_' + iDim] = np.mean\n",
    "    columnsForAveragingList['agg_influence_' + iDim] = np.mean\n",
    "    for jDim in timestampColumns:\n",
    "        columnsForAveragingList['influence_' + iDim + jDim] = np.mean\n",
    "columnsForAveragingList['decay'] = np.mean\n",
    "\n",
    "clusterHawkesParameterAve = dataset.groupby(['Modality', 'cluster']).agg(columnsForAveragingList).reset_index()\n",
    "clusterHawkesParameterAve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092a2940",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterHawkesParameterDiffResultsFullyOnline = clusterHawkesParameterDiffResults.loc[clusterHawkesParameterDiffResults['Modality'] == '(FULLY ONLINE)'][['index', 'is_significant']]\n",
    "clusterHawkesParameterDiffResultsHybrid = clusterHawkesParameterDiffResults.loc[clusterHawkesParameterDiffResults['Modality'] == '(HYBRID)'][['index', 'is_significant']]\n",
    "clusterHawkesParameterDiffResultsSignificance = clusterHawkesParameterDiffResultsFullyOnline.merge(clusterHawkesParameterDiffResultsHybrid, on=['index'])\n",
    "clusterHawkesParameterDiffResultsSignificance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a9f647",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparePValuesModalities(df):\n",
    "    return df['is_significant_x'] and df['is_significant_y']\n",
    "\n",
    "clusterHawkesParameterDiffResultsSignificance['both_significant'] = clusterHawkesParameterDiffResultsSignificance.apply(comparePValuesModalities, axis = 1)\n",
    "clusterHawkesParameterDiffResultsSignificance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afca86e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterHawkesParameterDiffResultsSignificance = clusterHawkesParameterDiffResultsSignificance.loc[~(clusterHawkesParameterDiffResultsSignificance['index'] == 'decay')]\n",
    "clusterHawkesParameterDiffResultsSignificance = clusterHawkesParameterDiffResultsSignificance[['index', 'both_significant']]\n",
    "clusterHawkesParameterDiffResultsSignificance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fbcf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixColorPerCluster(df):\n",
    "    if(df['both_significant'] == False):\n",
    "        if(df['cluster'] == 0):\n",
    "            return 'dimgray'\n",
    "        else:\n",
    "            return 'silver'\n",
    "    else:\n",
    "        if(df['cluster'] == 0):\n",
    "            return 'tab:blue'\n",
    "        else:\n",
    "            return 'tab:orange'\n",
    "\n",
    "for modality in modalities:\n",
    "    clusterHawkesParameterAveModality = clusterHawkesParameterAve.loc[clusterHawkesParameterAve['Modality'] == modality]\n",
    "    clusterHawkesParameterAveModality.drop(['Modality', 'decay'], axis = 1, inplace = True)\n",
    "    clusterHawkesParameterAveModality = clusterHawkesParameterAveModality.melt(id_vars='cluster', var_name='index', value_name='ave').reset_index()\n",
    "    \n",
    "    clusterHawkesParameterAveModality = clusterHawkesParameterAveModality.merge(clusterHawkesParameterDiffResultsSignificance, on=['index'])\n",
    "    clusterHawkesParameterAveModality['color'] = clusterHawkesParameterAveModality.apply(fixColorPerCluster, axis = 1)\n",
    "    \n",
    "    parameters = sorted(['baseline_' + dim for dim in timestampColumns] + adjacencyColumns() + ['agg_influence_' + dim for dim in timestampColumns], reverse = True)\n",
    "    x = np.arange(len(parameters))\n",
    "    width = 0.25\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    for cluster in [0, 1]:\n",
    "        offset = width * cluster\n",
    "        clusterHawkesParameterAveModalityCluster = clusterHawkesParameterAveModality.loc[clusterHawkesParameterAveModality['cluster'] == cluster].sort_values(by='index', ascending = False)\n",
    "        rects = ax.barh(x + offset, clusterHawkesParameterAveModalityCluster['ave'], width, color=clusterHawkesParameterAveModalityCluster['color'])\n",
    "    \n",
    "    ax.set_xlabel('Average Across Course-Student Pairs')\n",
    "    ax.set_ylabel('Multidimensional Hawkes Parameters')\n",
    "    ax.set_yticks(x + (width / 2), parameters)\n",
    "    fig.legend(handles=[Line2D([0], [0], color='tab:blue', label='Cluster 0, P-Value <= 0.001 for both Fully Online and Hybrid Classes'), Line2D([0], [0], color='tab:orange', label='Cluster 1, P-Value <= 0.001 for both Fully Online and Hybrid Classes'), Line2D([0], [0], color='dimgray', label='Cluster 0, P-Value > 0.001 for either Fully Online or Hybrid Classes'), Line2D([0], [0], color='silver', label='Cluster 1, P-Value > 0.001 for either Fully Online or Hybrid Classes')], ncols=4, loc='lower center')\n",
    "    plt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9, wspace=0.4, hspace=0.4)\n",
    "    fig.set_figwidth(50)\n",
    "    fig.set_figheight(10)\n",
    "    fig.savefig('ClusterHawkesParameterAve_' + modality + '.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6cae6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clusterHawkesParameterAve.to_csv(\"MultivariateHawkes_Metrics_Average_Groups.csv\", header = True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486bc13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.rename(columns={\"ave_delay_graded\": \"ave_delay_A\", \"ave_delay_ungraded\": \"ave_delay_C\"})\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6b4df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "delayPerClusterDiff = pd.DataFrame()\n",
    "\n",
    "for modality in modalities:\n",
    "    subDataset = dataset.loc[dataset['Modality'] == modality]\n",
    "    \n",
    "    for dim in timestampColumns:\n",
    "        result = {}\n",
    "        subDatasetDim = subDataset[['cluster', 'ave_delay_' + dim]]\n",
    "        subDatasetDim = subDatasetDim.dropna(subset=['ave_delay_' + dim])\n",
    "        \n",
    "        result['Modality'] = modality\n",
    "        result['dimension'] = dim\n",
    "        result['kruskal_stats'] = stats.kruskal(subDatasetDim.loc[subDatasetDim['cluster'] == 0]['ave_delay_' + dim], subDatasetDim.loc[subDatasetDim['cluster'] == 1]['ave_delay_' + dim]).statistic\n",
    "        result['kruskal_pval'] = stats.kruskal(subDatasetDim.loc[subDatasetDim['cluster'] == 0]['ave_delay_' + dim], subDatasetDim.loc[subDatasetDim['cluster'] == 1]['ave_delay_' + dim]).pvalue\n",
    "        delayPerClusterDiff = delayPerClusterDiff.append(result, ignore_index = True)\n",
    "\n",
    "delayPerClusterDiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8a9510",
   "metadata": {},
   "outputs": [],
   "source": [
    "delayPerClusterDiff['is_significant'] = delayPerClusterDiff['kruskal_pval'].apply(lambda x: x <= 0.001)\n",
    "delayPerClusterDiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1416e20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "delayPerClusterDiff['color'] = delayPerClusterDiff['is_significant'].apply(lambda x: 'tab:blue' if x else 'tab:gray')\n",
    "delayPerClusterDiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef51c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for modality in modalities:\n",
    "    delayPerClusterDiffModality = delayPerClusterDiff.loc[delayPerClusterDiff['Modality'] == modality]\n",
    "    delayPerClusterDiffModality.drop(['Modality'], axis = 1, inplace = True)\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(delayPerClusterDiffModality['dimension'], delayPerClusterDiffModality['kruskal_stats'], color=delayPerClusterDiffModality['color'])\n",
    "    ax.set_ylabel('Kruskal-Wallis Coefficient')\n",
    "    ax.set_xlabel('Multidimensional Hawkes Dimensions')\n",
    "    fig.legend(handles=[Line2D([0], [0], color='tab:blue', label='P-Value <= 0.001'), Line2D([0], [0], color='tab:gray', label='P-Value > 0.001')], loc='lower center')\n",
    "    plt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9, wspace=0.4, hspace=0.4)\n",
    "    fig.set_figwidth(10)\n",
    "    fig.set_figheight(10)\n",
    "    fig.savefig('DelayPerClusterDiff_' + modality + '.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5959eb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "averageDelayPerCluster = pd.DataFrame()\n",
    "\n",
    "for modality in modalities:\n",
    "    for cluster in dataset['cluster'].unique():\n",
    "        subDataset = dataset.loc[(dataset['Modality'] == modality) & (dataset['cluster'] == cluster)]\n",
    "        for dim in timestampColumns:\n",
    "            result = {'Modality': modality, 'cluster': cluster, 'dimension': dim}\n",
    "            subDataset = subDataset.dropna(subset=['ave_delay_' + dim])\n",
    "            result['ave_delay'] = np.mean(subDataset['ave_delay_' + dim])\n",
    "            averageDelayPerCluster = averageDelayPerCluster.append(result, ignore_index = True)\n",
    "\n",
    "averageDelayPerCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e09b417",
   "metadata": {},
   "outputs": [],
   "source": [
    "delayPerClusterDiffSignificance = delayPerClusterDiff[['Modality', 'dimension', 'is_significant']]\n",
    "delayPerClusterDiffSignificance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c39cbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "averageDelayPerCluster = averageDelayPerCluster.merge(delayPerClusterDiffSignificance, on=['Modality', 'dimension'])\n",
    "averageDelayPerCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8359a426",
   "metadata": {},
   "outputs": [],
   "source": [
    "for modality in modalities:\n",
    "    averageDelayPerClusterModality = averageDelayPerCluster.loc[averageDelayPerCluster['Modality'] == modality]\n",
    "    averageDelayPerClusterModality.drop(['Modality'], axis = 1, inplace = True)\n",
    "    averageDelayPerClusterModality = averageDelayPerClusterModality.rename(columns={'is_significant': 'both_significant'})\n",
    "    averageDelayPerClusterModality['color'] = averageDelayPerClusterModality.apply(fixColorPerCluster, axis = 1)\n",
    "    \n",
    "    dimensions = sorted(timestampColumns)\n",
    "    x = np.arange(len(dimensions))\n",
    "    width = 0.25\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    for cluster in [0, 1]:\n",
    "        offset = width * cluster\n",
    "        averageDelayPerClusterModalityCluster = averageDelayPerClusterModality.loc[averageDelayPerClusterModality['cluster'] == cluster].sort_values(by='dimension')\n",
    "        rects = ax.bar(x + offset, averageDelayPerClusterModalityCluster['ave_delay'], width, color=averageDelayPerClusterModalityCluster['color'])\n",
    "    \n",
    "    ax.set_ylabel('Average Delay Across Course-Student Pairs')\n",
    "    ax.set_xlabel('Multidimensional Hawkes Dimensions')\n",
    "    ax.set_xticks(x + (width / 2), dimensions)\n",
    "    fig.legend(handles=[Line2D([0], [0], color='tab:blue', label='Cluster 0, P-Value <= 0.001'), Line2D([0], [0], color='tab:orange', label='Cluster 1, P-Value <= 0.001'), Line2D([0], [0], color='dimgray', label='Cluster 0, P-Value > 0.001'), Line2D([0], [0], color='silver', label='Cluster 1, P-Value > 0.001')], loc='lower center')\n",
    "    plt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9, wspace=0.4, hspace=0.4)\n",
    "    fig.set_figwidth(10)\n",
    "    fig.set_figheight(15)\n",
    "    fig.savefig('AverageDelayPerCluster_' + modality + '.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b19fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjustedDelay(df, currentDim):\n",
    "    influenceBias = 0\n",
    "    for dim in timestampColumns:\n",
    "        if not (currentDim == dim):\n",
    "            influenceBias = influenceBias + (1 / (1 - df['influence_' + currentDim + dim]))\n",
    "    \n",
    "    return df['ave_delay_' + currentDim] + (1 / influenceBias)\n",
    "\n",
    "for dim in timestampColumns:\n",
    "    dataset['ave_delay_adj_' + dim] = dataset.apply(lambda df: adjustedDelay(df, dim), axis = 1)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3797c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "hawkesProcessSpearmanCorrelationGrades = pd.DataFrame()\n",
    "\n",
    "for modality in modalities:\n",
    "    hawkesProcessResultSubset = dataset.loc[dataset['Modality'] == modality]\n",
    "    for dim in timestampColumns:\n",
    "        spearmanCorrelationResultDelay = stats.spearmanr(hawkesProcessResultSubset['est_course_grade'], hawkesProcessResultSubset['ave_delay_' + dim])\n",
    "        spearmanCorrelationResultDelayAdj = stats.spearmanr(hawkesProcessResultSubset['est_course_grade'], hawkesProcessResultSubset['ave_delay_adj_' + dim])\n",
    "        hawkesProcessSpearmanCorrelationGrades = hawkesProcessSpearmanCorrelationGrades.append(pd.DataFrame.from_dict([{'Modality': modality, 'dimension': dim, 'coefficient_delay': spearmanCorrelationResultDelay.correlation, 'p_delay': spearmanCorrelationResultDelay.pvalue, 'coefficient_delay_adj': spearmanCorrelationResultDelayAdj.correlation, 'p_delay_adj': spearmanCorrelationResultDelayAdj.pvalue}]), ignore_index = True)\n",
    "\n",
    "for suffix in ['', '_adj']:\n",
    "    hawkesProcessSpearmanCorrelationGrades['coefficient_delay' + suffix] = hawkesProcessSpearmanCorrelationGrades['coefficient_delay' + suffix].apply(lambda x: round(x, 2))\n",
    "    hawkesProcessSpearmanCorrelationGrades['p_delay' + suffix] = hawkesProcessSpearmanCorrelationGrades['p_delay' + suffix].apply(lambda x: round(x, 2))\n",
    "        \n",
    "hawkesProcessSpearmanCorrelationGrades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8d259c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hawkesProcessSpearmanCorrelationGrades.to_csv(\"MultidimensionalHawkesParametersDelayCorrGrades.csv\", header = True, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
